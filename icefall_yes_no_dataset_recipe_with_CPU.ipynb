{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/Jaime44/KUNVENO/blob/main/icefall_yes_no_dataset_recipe_with_CPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"cC0w8FMdN1j1"},"source":["# Yesno recipe in icefall\n","\n","This notebook shows you how to setup the environment to use [icefall][icefall] for training and decoding.\n","It also describes how to use a per-trained model to decode waves.\n","\n","\n","We use the [yesno] dataset as an example.\n","\n","[icefall]: https://github.com/k2-fsa/icefall\n","[yesno]: https://www.openslr.org/1/"]},{"cell_type":"markdown","metadata":{"id":"s8jMkYeDQUeY"},"source":["## Environment setup"]},{"cell_type":"markdown","metadata":{"id":"Etfavk8FQXRQ"},"source":["### Install PyTorch and torchaudio"]},{"cell_type":"code","source":["import sys\n","import os\n","\n","\n","# Comprueba si el código se está ejecutando en Google Colab\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False\n","\n","path_absolute = ''\n","if IN_COLAB:\n","    print(\"El código se está ejecutando en Google Colab.\")\n","    from google.colab import drive\n","\n","    drive.mount('/content/drive')\n","    path_absolute = '/content/drive/Othercomputers/Mi portátil/KUNVENO/KUNVENO_DIGITAL/'\n","\n","    # Cambia al directorio de tu carpeta en Google Drive\n","    os.chdir(path_absolute)\n","\n","    # Lista los archivos y carpetas en el directorio actual\n","    contenido_carpeta = os.listdir(path_absolute)\n","    print(\"Contenido de la carpeta en Google Drive:\")\n","    print(contenido_carpeta)\n","else:\n","    print(\"El código se está ejecutando en un entorno local.\")\n","    path_absolute = 'C:/Users/jaime/OneDrive - Universidad de Málaga/Escritorio/UNIR/PRÁCITCAS EXT/KUNVENO/KUNVENO_DIGITAL/'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fp5LmDJlxa5u","executionInfo":{"status":"ok","timestamp":1697045292644,"user_tz":-120,"elapsed":28032,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"491389d2-15e4-4867-8d22-64000ad49452"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["El código se está ejecutando en Google Colab.\n","Mounted at /content/drive\n","Contenido de la carpeta en Google Drive:\n","['icefall_yes_no_dataset_recipe_with_CPU.ipynb', 'Git_commnads.txt', '.git', 'README.md', '.gitignore', 'checkpoints']\n"]}]},{"cell_type":"code","source":["pat_dir_checkpoints = path_absolute+'checkpoints'"],"metadata":{"id":"WMwhlcrAyL5D"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"AliAaueDNteG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697043873530,"user_tz":-120,"elapsed":6,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"edaeeed0-cd63-470d-af32-24ef52eca37f"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.1+cu118\n"]}],"source":["import torch\n","print(torch.__version__)"]},{"cell_type":"markdown","metadata":{"id":"aXyznh4VaZVj"},"source":["Colab pre-installs PyTorch, so we don't need to install it here.\n","\n","From https://pytorch.org/audio/main/installation.html#compatibility-matrix, we need to install torchaudio==2.0.2 as the current PyTorch version is 2.0.1"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"OJzBhtJAQbD6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697043879715,"user_tz":-120,"elapsed":6188,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"c8c7f770-b73e-4d5f-bad6-8b7f67c3e1f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchaudio==2.0.2 in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n","Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio==2.0.2) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchaudio==2.0.2) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchaudio==2.0.2) (17.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchaudio==2.0.2) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchaudio==2.0.2) (1.3.0)\n"]}],"source":["! pip install torchaudio==2.0.2"]},{"cell_type":"markdown","metadata":{"id":"G0HY88GiR7_J"},"source":["### Install k2\n","\n","We are going to install k2 by following https://k2-fsa.github.io/k2/installation/from_wheels.html.\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8JccZFPBQ7vJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697043897314,"user_tz":-120,"elapsed":17607,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"b57c5dba-ea12-4d51-cd63-096db996e295"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://k2-fsa.github.io/k2/cuda.html\n","Collecting k2==1.24.3.dev20230718+cuda11.8.torch2.0.1\n","  Downloading https://huggingface.co/csukuangfj/k2/resolve/main/cuda/k2-1.24.3.dev20230718%2Bcuda11.8.torch2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.9/117.9 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from k2==1.24.3.dev20230718+cuda11.8.torch2.0.1) (2.0.1+cu118)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from k2==1.24.3.dev20230718+cuda11.8.torch2.0.1) (0.20.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.8.torch2.0.1) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.8.torch2.0.1) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.8.torch2.0.1) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.8.torch2.0.1) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.8.torch2.0.1) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.8.torch2.0.1) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->k2==1.24.3.dev20230718+cuda11.8.torch2.0.1) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->k2==1.24.3.dev20230718+cuda11.8.torch2.0.1) (17.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->k2==1.24.3.dev20230718+cuda11.8.torch2.0.1) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->k2==1.24.3.dev20230718+cuda11.8.torch2.0.1) (1.3.0)\n","Installing collected packages: k2\n","Successfully installed k2-1.24.3.dev20230718+cuda11.8.torch2.0.1\n"]}],"source":["! pip install k2==1.24.3.dev20230718+cuda11.8.torch2.0.1 -f https://k2-fsa.github.io/k2/cuda.html"]},{"cell_type":"markdown","metadata":{"id":"-Jl3lHExSTSI"},"source":["Check that k2 was installed successfully:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"cYnIIeh6SPz9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697043900603,"user_tz":-120,"elapsed":3306,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"bd9e6457-a606-4b1a-a8bc-9ab6fcc18fbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting environment information...\n","\n","k2 version: 1.24.3\n","Build type: Release\n","Git SHA1: e400fa3b456faf8afe0ee5bfe572946b4921a3db\n","Git date: Sat Jul 15 04:21:50 2023\n","Cuda used to build k2: 11.8\n","cuDNN used to build k2: \n","Python version used to build k2: 3.10\n","OS used to build k2: CentOS Linux release 7.9.2009 (Core)\n","CMake version: 3.26.4\n","GCC version: 9.3.1\n","CMAKE_CUDA_FLAGS:  -Wno-deprecated-gpu-targets   -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_35,code=sm_35  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_50,code=sm_50  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_60,code=sm_60  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_61,code=sm_61  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_70,code=sm_70  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_75,code=sm_75  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_80,code=sm_80  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_86,code=sm_86 -DONNX_NAMESPACE=onnx_c2 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_90,code=sm_90 -gencode arch=compute_89,code=compute_89 -gencode arch=compute_90,code=compute_90 -Xcudafe --diag_suppress=cc_clobber_ignored,--diag_suppress=integer_sign_change,--diag_suppress=useless_using_declaration,--diag_suppress=set_but_not_used,--diag_suppress=field_without_dll_interface,--diag_suppress=base_class_has_different_dll_interface,--diag_suppress=dll_interface_conflict_none_assumed,--diag_suppress=dll_interface_conflict_dllexport_assumed,--diag_suppress=implicit_return_from_non_void_function,--diag_suppress=unsigned_compare_with_zero,--diag_suppress=declared_but_not_referenced,--diag_suppress=bad_friend_decl --expt-relaxed-constexpr --expt-extended-lambda -D_GLIBCXX_USE_CXX11_ABI=0 --compiler-options -Wall  --compiler-options -Wno-strict-overflow  --compiler-options -Wno-unknown-pragmas \n","CMAKE_CXX_FLAGS:  -D_GLIBCXX_USE_CXX11_ABI=0 -Wno-unused-variable  -Wno-strict-overflow \n","PyTorch version used to build k2: 2.0.1+cu118\n","PyTorch is using Cuda: 11.8\n","NVTX enabled: True\n","With CUDA: True\n","Disable debug: True\n","Sync kernels : False\n","Disable checks: False\n","Max cpu memory allocate: 214748364800 bytes (or 200.0 GB)\n","k2 abort: False\n","__file__: /usr/local/lib/python3.10/dist-packages/k2/version/version.py\n","_k2.__file__: /usr/local/lib/python3.10/dist-packages/_k2.cpython-310-x86_64-linux-gnu.so\n","    \n"]}],"source":["! python3 -m k2.version"]},{"cell_type":"markdown","metadata":{"id":"biN4HMqFSdJ5"},"source":["### Install lhotse\n","[lhotse][lhotse] is used for data preparation.\n","\n","[lhotse]: https://github.com/lhotse-speech/lhotse\n","\n","Normally, we would use `pip install lhotse`. However, the yesno recipe is added recently and has not been released to PyPI yet, so we install the latest unreleased version here."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6SsFZwCESWz_","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1697043924326,"user_tz":-120,"elapsed":23726,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"6649fe96-fa02-48f8-d906-d5c05f280f23"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lhotse\n","  Downloading lhotse-1.17.0-py3-none-any.whl (731 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.9/731.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from lhotse) (3.0.1)\n","Requirement already satisfied: SoundFile>=0.10 in /usr/local/lib/python3.10/dist-packages (from lhotse) (0.12.1)\n","Requirement already satisfied: click>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from lhotse) (8.1.7)\n","Collecting cytoolz>=0.10.1 (from lhotse)\n","  Downloading cytoolz-0.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dataclasses (from lhotse)\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Collecting intervaltree>=3.1.0 (from lhotse)\n","  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from lhotse) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lhotse) (23.2)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from lhotse) (6.0.1)\n","Requirement already satisfied: tabulate>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from lhotse) (0.9.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lhotse) (4.66.1)\n","Collecting lilcom>=1.1.0 (from lhotse)\n","  Downloading lilcom-1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz>=0.10.1->lhotse) (0.12.0)\n","Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from intervaltree>=3.1.0->lhotse) (2.4.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10->lhotse) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10->lhotse) (2.21)\n","Building wheels for collected packages: intervaltree\n","  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26094 sha256=53dff312e3e32c02223d7674f4655404a1b3033f965d9c5eee5aa5f3487c2a44\n","  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n","Successfully built intervaltree\n","Installing collected packages: dataclasses, lilcom, intervaltree, cytoolz, lhotse\n","Successfully installed cytoolz-0.12.2 dataclasses-0.6 intervaltree-3.1.0 lhotse-1.17.0 lilcom-1.7\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dataclasses"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/lhotse-speech/lhotse\n","  Cloning https://github.com/lhotse-speech/lhotse to /tmp/pip-req-build-ccol7_aj\n","  Running command git clone --filter=blob:none --quiet https://github.com/lhotse-speech/lhotse /tmp/pip-req-build-ccol7_aj\n","  Resolved https://github.com/lhotse-speech/lhotse to commit afc8eff1d1eaeeae42e0a628e1981bb231527340\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (3.0.1)\n","Requirement already satisfied: SoundFile>=0.10 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (0.12.1)\n","Requirement already satisfied: click>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (8.1.7)\n","Requirement already satisfied: cytoolz>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (0.12.2)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (0.6)\n","Requirement already satisfied: intervaltree>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (3.1.0)\n","Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (23.2)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (6.0.1)\n","Requirement already satisfied: tabulate>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (0.9.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (4.66.1)\n","Requirement already satisfied: lilcom>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (1.7)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (2.0.1+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from lhotse==1.17.0.dev0+git.afc8eff.clean) (2.0.2+cu118)\n","Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz>=0.10.1->lhotse==1.17.0.dev0+git.afc8eff.clean) (0.12.0)\n","Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from intervaltree>=3.1.0->lhotse==1.17.0.dev0+git.afc8eff.clean) (2.4.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10->lhotse==1.17.0.dev0+git.afc8eff.clean) (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.17.0.dev0+git.afc8eff.clean) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.17.0.dev0+git.afc8eff.clean) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.17.0.dev0+git.afc8eff.clean) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.17.0.dev0+git.afc8eff.clean) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.17.0.dev0+git.afc8eff.clean) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.17.0.dev0+git.afc8eff.clean) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->lhotse==1.17.0.dev0+git.afc8eff.clean) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->lhotse==1.17.0.dev0+git.afc8eff.clean) (17.0.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10->lhotse==1.17.0.dev0+git.afc8eff.clean) (2.21)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->lhotse==1.17.0.dev0+git.afc8eff.clean) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->lhotse==1.17.0.dev0+git.afc8eff.clean) (1.3.0)\n","Building wheels for collected packages: lhotse\n","  Building wheel for lhotse (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lhotse: filename=lhotse-1.17.0.dev0+git.afc8eff.clean-py3-none-any.whl size=732280 sha256=6bbd3d3a171e3b286a7ada300c0aca98ee4436c5f1f2a49222ec2ec79e76a9e7\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-5oltbn3o/wheels/df/b0/ff/cce0f16868fcdbee2088f3acf9f249dc90117d5f5dd9b6f69d\n","Successfully built lhotse\n","Installing collected packages: lhotse\n","  Attempting uninstall: lhotse\n","    Found existing installation: lhotse 1.17.0\n","    Uninstalling lhotse-1.17.0:\n","      Successfully uninstalled lhotse-1.17.0\n","Successfully installed lhotse-1.17.0.dev0+git.afc8eff.clean\n"]}],"source":["! pip install lhotse\n","! pip install git+https://github.com/lhotse-speech/lhotse"]},{"cell_type":"markdown","metadata":{"id":"Jwq8uAGpSyzu"},"source":["### Install icefall"]},{"cell_type":"markdown","metadata":{"id":"7ivIXM8FS0Yy"},"source":["[icefall][icefall] is a collection of Python scripts.\n","You don't need to install it. What you need to do is\n","to get its source code, install its dependencies, and\n","set the `PYTHONPATH` pointing to it.\n","\n","[icefall]: https://github.com/k2-fsa/icefall"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"aflfLSytSnFe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697043924326,"user_tz":-120,"elapsed":7,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"cd99a817-2b4c-4978-8eb8-8ebeb8bc14b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["! pwd"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"KP4RZ31xTKzL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697043928288,"user_tz":-120,"elapsed":3966,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"ee9e21e7-5235-48e6-b56d-3b4355850f89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'icefall'...\n","remote: Enumerating objects: 14438, done.\u001b[K\n","remote: Counting objects: 100% (54/54), done.\u001b[K\n","remote: Compressing objects: 100% (49/49), done.\u001b[K\n","remote: Total 14438 (delta 14), reused 11 (delta 3), pack-reused 14384\u001b[K\n","Receiving objects: 100% (14438/14438), 16.60 MiB | 15.80 MiB/s, done.\n","Resolving deltas: 100% (9891/9891), done.\n"]}],"source":["! git clone https://github.com/k2-fsa/icefall"]},{"cell_type":"markdown","metadata":{"id":"S1c5zESwTtii"},"source":["Now install dependencies of `icefall`:"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"TYOwkp6FTrdH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697043943849,"user_tz":-120,"elapsed":15573,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"7f3efb3f-8c51-456b-f0e8-7e1e0f7dd7a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kaldifst (from -r requirements.txt (line 1))\n","  Downloading kaldifst-1.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kaldilm (from -r requirements.txt (line 2))\n","  Downloading kaldilm-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kaldialign (from -r requirements.txt (line 3))\n","  Downloading kaldialign-0.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kaldi-decoder (from -r requirements.txt (line 4))\n","  Downloading kaldi_decoder-0.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (982 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentencepiece>=0.1.96 (from -r requirements.txt (line 5))\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.13.0)\n","Collecting typeguard (from -r requirements.txt (line 7))\n","  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n","Collecting dill (from -r requirements.txt (line 8))\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting black==22.3.0 (from -r requirements.txt (line 9))\n","  Downloading black-22.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->-r requirements.txt (line 9)) (8.1.7)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->-r requirements.txt (line 9)) (3.11.0)\n","Collecting pathspec>=0.9.0 (from black==22.3.0->-r requirements.txt (line 9))\n","  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n","Collecting mypy-extensions>=0.4.3 (from black==22.3.0->-r requirements.txt (line 9))\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->-r requirements.txt (line 9)) (2.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.59.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.4.4)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.23.5)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.31.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.0.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.41.2)\n","Collecting typing-extensions>=4.7.0 (from typeguard->-r requirements.txt (line 7))\n","  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 6)) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 6)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 6)) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 6)) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 6)) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 6)) (3.2.2)\n","Installing collected packages: sentencepiece, kaldilm, kaldifst, kaldialign, typing-extensions, pathspec, mypy-extensions, kaldi-decoder, dill, typeguard, black\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed black-22.3.0 dill-0.3.7 kaldi-decoder-0.2.3 kaldialign-0.7.2 kaldifst-1.7.5 kaldilm-1.15.1 mypy-extensions-1.0.0 pathspec-0.11.2 sentencepiece-0.1.99 typeguard-4.1.5 typing-extensions-4.8.0\n"]}],"source":["! cd icefall && \\\n","  pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"jeFyXWEOT4Mi"},"source":["## Data preparation"]},{"cell_type":"markdown","metadata":{"id":"HqMH7ZLKT8jM"},"source":["We have set up the environment. Now it is the time to prepare data for training and decoding.\n","\n","As we just said, `icefall` is a collection of Python scripts and we have to set up the `PYTHONPATH` variable to use it. Remember that `icefall` was downloaded to\n","`/content/icefall`, so we use\n","\n","```\n","export PYTHONPATH=/content/icefall:$PYTHONPATH\n","```\n","\n","**HINT**: You can have several versions of `icefall` in your virtual environemnt. To switch to a specific version of `icefall`, just change the `PYTHONPATH` environment variable."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"7YQUEXWruxFu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697043959263,"user_tz":-120,"elapsed":15431,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"20d8adc9-19e4-4a11-f06c-5308e829c557"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.13.0\n","Uninstalling tensorflow-2.13.0:\n","  Successfully uninstalled tensorflow-2.13.0\n"]}],"source":["# To remove the following warning message\n","# 2023-07-27 05:03:07.156920: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","! pip uninstall -y tensorflow"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Vzyw8VyfUjUB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697043982242,"user_tz":-120,"elapsed":22986,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"ddb89517-dc68-410e-f773-0c4bc3532bf0"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-11 17:05:56 (prepare.sh:27:main) dl_dir: /content/icefall/egs/yesno/ASR/download\n","2023-10-11 17:05:56 (prepare.sh:30:main) Stage 0: Download data\n","/content/icefall/egs/yesno/ASR/download/waves_yesno.tar.gz: 100% 4.70M/4.70M [00:01<00:00, 2.82MB/s]\n","2023-10-11 17:06:02 (prepare.sh:39:main) Stage 1: Prepare yesno manifest\n","2023-10-11 17:06:04 (prepare.sh:45:main) Stage 2: Compute fbank for yesno\n","2023-10-11 17:06:10,597 INFO [compute_fbank_yesno.py:65] Processing train\n","Extracting and storing features: 100% 90/90 [00:00<00:00, 175.98it/s]\n","2023-10-11 17:06:11,130 INFO [compute_fbank_yesno.py:65] Processing test\n","Extracting and storing features: 100% 30/30 [00:00<00:00, 305.68it/s]\n","2023-10-11 17:06:11 (prepare.sh:51:main) Stage 3: Prepare lang\n","2023-10-11 17:06:16,259 INFO [prepare_lang_fst.py:174] Building standard CTC topology\n","2023-10-11 17:06:16,260 INFO [prepare_lang_fst.py:183] Building L\n","2023-10-11 17:06:16,260 INFO [prepare_lang_fst.py:191] Building HL\n","2023-10-11 17:06:16,261 INFO [prepare_lang_fst.py:201] Skip building HLG\n","2023-10-11 17:06:16 (prepare.sh:67:main) Stage 4: Prepare G\n","/project/kaldilm/csrc/arpa_file_parser.cc:void kaldilm::ArpaFileParser::Read(std::istream&):79\n","[I] Reading \\data\\ section.\n","/project/kaldilm/csrc/arpa_file_parser.cc:void kaldilm::ArpaFileParser::Read(std::istream&):140\n","[I] Reading \\1-grams: section.\n","2023-10-11 17:06:16 (prepare.sh:93:main) Stage 5: Compile HLG\n","2023-10-11 17:06:18,665 INFO [compile_hlg.py:124] Processing data/lang_phone\n","2023-10-11 17:06:18,665 INFO [lexicon.py:171] Converting L.pt to Linv.pt\n","2023-10-11 17:06:18,667 INFO [compile_hlg.py:48] Building ctc_topo. max_token_id: 3\n","2023-10-11 17:06:18,668 INFO [compile_hlg.py:52] Loading G.fst.txt\n","2023-10-11 17:06:18,668 INFO [compile_hlg.py:62] Intersecting L and G\n","2023-10-11 17:06:18,669 INFO [compile_hlg.py:64] LG shape: (4, None)\n","2023-10-11 17:06:18,669 INFO [compile_hlg.py:66] Connecting LG\n","2023-10-11 17:06:18,669 INFO [compile_hlg.py:68] LG shape after k2.connect: (4, None)\n","2023-10-11 17:06:18,669 INFO [compile_hlg.py:70] <class 'torch.Tensor'>\n","2023-10-11 17:06:18,669 INFO [compile_hlg.py:71] Determinizing LG\n","2023-10-11 17:06:18,671 INFO [compile_hlg.py:74] <class '_k2.ragged.RaggedTensor'>\n","2023-10-11 17:06:18,671 INFO [compile_hlg.py:76] Connecting LG after k2.determinize\n","2023-10-11 17:06:18,671 INFO [compile_hlg.py:79] Removing disambiguation symbols on LG\n","2023-10-11 17:06:18,672 INFO [compile_hlg.py:91] LG shape after k2.remove_epsilon: (6, None)\n","2023-10-11 17:06:18,673 INFO [compile_hlg.py:96] Arc sorting LG\n","2023-10-11 17:06:18,673 INFO [compile_hlg.py:99] Composing H and LG\n","2023-10-11 17:06:18,673 INFO [compile_hlg.py:106] Connecting LG\n","2023-10-11 17:06:18,673 INFO [compile_hlg.py:109] Arc sorting LG\n","2023-10-11 17:06:18,674 INFO [compile_hlg.py:111] HLG.shape: (8, None)\n","2023-10-11 17:06:18,674 INFO [compile_hlg.py:127] Saving HLG.pt to data/lang_phone\n"]}],"source":["! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n","  cd /content/icefall/egs/yesno/ASR && \\\n","  rm -rf data && \\\n","  ./prepare.sh"]},{"cell_type":"markdown","metadata":{"id":"9RAnFhhqZgPo"},"source":["## Training"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"1phegInRZkbl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044024980,"user_tz":-120,"elapsed":42750,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"52383342-f765-44cf-ba48-d94ebfcfc324"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-11 17:06:22,028 INFO [train.py:481] Training started\n","2023-10-11 17:06:22,028 INFO [train.py:482] {'exp_dir': PosixPath('tdnn/exp'), 'lang_dir': PosixPath('data/lang_phone'), 'lr': 0.01, 'feature_dim': 23, 'weight_decay': 1e-06, 'start_epoch': 0, 'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 10, 'reset_interval': 20, 'valid_interval': 10, 'beam_size': 10, 'reduction': 'sum', 'use_double_scores': True, 'world_size': 1, 'master_port': 12354, 'tensorboard': True, 'num_epochs': 15, 'seed': 42, 'feature_dir': PosixPath('data/fbank'), 'max_duration': 30.0, 'bucketing_sampler': False, 'num_buckets': 10, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': False, 'return_cuts': True, 'num_workers': 2, 'env_info': {'k2-version': '1.24.3', 'k2-build-type': 'Release', 'k2-with-cuda': True, 'k2-git-sha1': 'e400fa3b456faf8afe0ee5bfe572946b4921a3db', 'k2-git-date': 'Sat Jul 15 04:21:50 2023', 'lhotse-version': '1.17.0.dev+git.afc8eff.clean', 'torch-version': '2.0.1+cu118', 'torch-cuda-available': True, 'torch-cuda-version': '11.8', 'python-version': '3.1', 'icefall-git-branch': 'master', 'icefall-git-sha1': '2b3c5d7-clean', 'icefall-git-date': 'Wed Oct 11 08:58:00 2023', 'icefall-path': '/content/icefall', 'k2-path': '/usr/local/lib/python3.10/dist-packages/k2/__init__.py', 'lhotse-path': '/usr/local/lib/python3.10/dist-packages/lhotse/__init__.py', 'hostname': 'df0af0b2b89f', 'IP address': '172.28.0.12'}}\n","2023-10-11 17:06:22,030 INFO [lexicon.py:168] Loading pre-compiled data/lang_phone/Linv.pt\n","2023-10-11 17:06:22,032 INFO [train.py:495] device: cuda:0\n","2023-10-11 17:06:27,515 INFO [asr_datamodule.py:146] About to get train cuts\n","2023-10-11 17:06:27,515 INFO [asr_datamodule.py:245] About to get train cuts\n","2023-10-11 17:06:28,026 INFO [asr_datamodule.py:149] About to create train dataset\n","2023-10-11 17:06:28,027 INFO [asr_datamodule.py:199] Using SimpleCutSampler.\n","2023-10-11 17:06:28,027 INFO [asr_datamodule.py:205] About to create train dataloader\n","2023-10-11 17:06:28,027 INFO [asr_datamodule.py:218] About to get test cuts\n","2023-10-11 17:06:28,027 INFO [asr_datamodule.py:253] About to get test cuts\n","2023-10-11 17:06:36,045 INFO [train.py:422] Epoch 0, batch 0, loss[loss=1.065, over 2436.00 frames. ], tot_loss[loss=1.065, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:36,746 INFO [train.py:422] Epoch 0, batch 10, loss[loss=0.4633, over 2828.00 frames. ], tot_loss[loss=0.7099, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:37,366 INFO [train.py:444] Epoch 0, validation loss=0.9356, over 18067.00 frames. \n","2023-10-11 17:06:38,047 INFO [train.py:422] Epoch 0, batch 20, loss[loss=0.2629, over 2695.00 frames. ], tot_loss[loss=0.488, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:38,403 INFO [train.py:444] Epoch 0, validation loss=0.5138, over 18067.00 frames. \n","2023-10-11 17:06:38,446 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-0.pt\n","2023-10-11 17:06:38,503 INFO [train.py:422] Epoch 1, batch 0, loss[loss=0.2587, over 2436.00 frames. ], tot_loss[loss=0.2587, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:38,916 INFO [train.py:422] Epoch 1, batch 10, loss[loss=0.1258, over 2828.00 frames. ], tot_loss[loss=0.1666, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:39,199 INFO [train.py:444] Epoch 1, validation loss=0.147, over 18067.00 frames. \n","2023-10-11 17:06:39,583 INFO [train.py:422] Epoch 1, batch 20, loss[loss=0.07638, over 2695.00 frames. ], tot_loss[loss=0.1221, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:39,874 INFO [train.py:444] Epoch 1, validation loss=0.07156, over 18067.00 frames. \n","2023-10-11 17:06:39,910 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-1.pt\n","2023-10-11 17:06:39,964 INFO [train.py:422] Epoch 2, batch 0, loss[loss=0.07919, over 2436.00 frames. ], tot_loss[loss=0.07919, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:40,362 INFO [train.py:422] Epoch 2, batch 10, loss[loss=0.044, over 2828.00 frames. ], tot_loss[loss=0.05531, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:40,651 INFO [train.py:444] Epoch 2, validation loss=0.04926, over 18067.00 frames. \n","2023-10-11 17:06:41,039 INFO [train.py:422] Epoch 2, batch 20, loss[loss=0.03392, over 2695.00 frames. ], tot_loss[loss=0.04656, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:41,324 INFO [train.py:444] Epoch 2, validation loss=0.03681, over 18067.00 frames. \n","2023-10-11 17:06:41,363 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-2.pt\n","2023-10-11 17:06:41,420 INFO [train.py:422] Epoch 3, batch 0, loss[loss=0.03536, over 2436.00 frames. ], tot_loss[loss=0.03536, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:41,824 INFO [train.py:422] Epoch 3, batch 10, loss[loss=0.02345, over 2828.00 frames. ], tot_loss[loss=0.02773, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:42,111 INFO [train.py:444] Epoch 3, validation loss=0.02515, over 18067.00 frames. \n","2023-10-11 17:06:42,496 INFO [train.py:422] Epoch 3, batch 20, loss[loss=0.02255, over 2695.00 frames. ], tot_loss[loss=0.02633, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:42,795 INFO [train.py:444] Epoch 3, validation loss=0.02279, over 18067.00 frames. \n","2023-10-11 17:06:42,834 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-3.pt\n","2023-10-11 17:06:42,890 INFO [train.py:422] Epoch 4, batch 0, loss[loss=0.02116, over 2436.00 frames. ], tot_loss[loss=0.02116, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:43,326 INFO [train.py:422] Epoch 4, batch 10, loss[loss=0.01621, over 2828.00 frames. ], tot_loss[loss=0.01874, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:43,616 INFO [train.py:444] Epoch 4, validation loss=0.01969, over 18067.00 frames. \n","2023-10-11 17:06:44,014 INFO [train.py:422] Epoch 4, batch 20, loss[loss=0.01673, over 2695.00 frames. ], tot_loss[loss=0.01892, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:44,299 INFO [train.py:444] Epoch 4, validation loss=0.01854, over 18067.00 frames. \n","2023-10-11 17:06:44,335 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-4.pt\n","2023-10-11 17:06:44,391 INFO [train.py:422] Epoch 5, batch 0, loss[loss=0.01749, over 2436.00 frames. ], tot_loss[loss=0.01749, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:44,786 INFO [train.py:422] Epoch 5, batch 10, loss[loss=0.01255, over 2828.00 frames. ], tot_loss[loss=0.01489, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:45,079 INFO [train.py:444] Epoch 5, validation loss=0.01508, over 18067.00 frames. \n","2023-10-11 17:06:45,610 INFO [train.py:422] Epoch 5, batch 20, loss[loss=0.01459, over 2695.00 frames. ], tot_loss[loss=0.01599, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:45,944 INFO [train.py:444] Epoch 5, validation loss=0.01378, over 18067.00 frames. \n","2023-10-11 17:06:45,980 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-5.pt\n","2023-10-11 17:06:46,035 INFO [train.py:422] Epoch 6, batch 0, loss[loss=0.01395, over 2436.00 frames. ], tot_loss[loss=0.01395, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:46,437 INFO [train.py:422] Epoch 6, batch 10, loss[loss=0.01106, over 2828.00 frames. ], tot_loss[loss=0.01279, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:46,750 INFO [train.py:444] Epoch 6, validation loss=0.01344, over 18067.00 frames. \n","2023-10-11 17:06:47,150 INFO [train.py:422] Epoch 6, batch 20, loss[loss=0.01348, over 2695.00 frames. ], tot_loss[loss=0.01353, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:47,440 INFO [train.py:444] Epoch 6, validation loss=0.01258, over 18067.00 frames. \n","2023-10-11 17:06:47,479 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-6.pt\n","2023-10-11 17:06:47,532 INFO [train.py:422] Epoch 7, batch 0, loss[loss=0.01251, over 2436.00 frames. ], tot_loss[loss=0.01251, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:47,939 INFO [train.py:422] Epoch 7, batch 10, loss[loss=0.01024, over 2828.00 frames. ], tot_loss[loss=0.01148, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:48,222 INFO [train.py:444] Epoch 7, validation loss=0.01241, over 18067.00 frames. \n","2023-10-11 17:06:48,810 INFO [train.py:422] Epoch 7, batch 20, loss[loss=0.0128, over 2695.00 frames. ], tot_loss[loss=0.01252, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:49,262 INFO [train.py:444] Epoch 7, validation loss=0.01194, over 18067.00 frames. \n","2023-10-11 17:06:49,317 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-7.pt\n","2023-10-11 17:06:49,406 INFO [train.py:422] Epoch 8, batch 0, loss[loss=0.0119, over 2436.00 frames. ], tot_loss[loss=0.0119, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:50,032 INFO [train.py:422] Epoch 8, batch 10, loss[loss=0.009795, over 2828.00 frames. ], tot_loss[loss=0.01097, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:50,488 INFO [train.py:444] Epoch 8, validation loss=0.01193, over 18067.00 frames. \n","2023-10-11 17:06:51,051 INFO [train.py:422] Epoch 8, batch 20, loss[loss=0.0125, over 2695.00 frames. ], tot_loss[loss=0.01159, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:51,512 INFO [train.py:444] Epoch 8, validation loss=0.01139, over 18067.00 frames. \n","2023-10-11 17:06:51,567 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-8.pt\n","2023-10-11 17:06:51,651 INFO [train.py:422] Epoch 9, batch 0, loss[loss=0.01127, over 2436.00 frames. ], tot_loss[loss=0.01127, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:52,260 INFO [train.py:422] Epoch 9, batch 10, loss[loss=0.009509, over 2828.00 frames. ], tot_loss[loss=0.01064, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:52,691 INFO [train.py:444] Epoch 9, validation loss=0.01147, over 18067.00 frames. \n","2023-10-11 17:06:53,089 INFO [train.py:422] Epoch 9, batch 20, loss[loss=0.01217, over 2695.00 frames. ], tot_loss[loss=0.0112, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:53,390 INFO [train.py:444] Epoch 9, validation loss=0.01121, over 18067.00 frames. \n","2023-10-11 17:06:53,427 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-9.pt\n","2023-10-11 17:06:53,485 INFO [train.py:422] Epoch 10, batch 0, loss[loss=0.01109, over 2436.00 frames. ], tot_loss[loss=0.01109, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:53,895 INFO [train.py:422] Epoch 10, batch 10, loss[loss=0.00929, over 2828.00 frames. ], tot_loss[loss=0.0103, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:54,193 INFO [train.py:444] Epoch 10, validation loss=0.01143, over 18067.00 frames. \n","2023-10-11 17:06:54,586 INFO [train.py:422] Epoch 10, batch 20, loss[loss=0.01197, over 2695.00 frames. ], tot_loss[loss=0.01121, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:54,870 INFO [train.py:444] Epoch 10, validation loss=0.01107, over 18067.00 frames. \n","2023-10-11 17:06:54,905 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-10.pt\n","2023-10-11 17:06:54,962 INFO [train.py:422] Epoch 11, batch 0, loss[loss=0.01082, over 2436.00 frames. ], tot_loss[loss=0.01082, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:55,363 INFO [train.py:422] Epoch 11, batch 10, loss[loss=0.009133, over 2828.00 frames. ], tot_loss[loss=0.01011, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:55,658 INFO [train.py:444] Epoch 11, validation loss=0.01118, over 18067.00 frames. \n","2023-10-11 17:06:56,046 INFO [train.py:422] Epoch 11, batch 20, loss[loss=0.01185, over 2695.00 frames. ], tot_loss[loss=0.01081, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:56,345 INFO [train.py:444] Epoch 11, validation loss=0.01094, over 18067.00 frames. \n","2023-10-11 17:06:56,381 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-11.pt\n","2023-10-11 17:06:56,436 INFO [train.py:422] Epoch 12, batch 0, loss[loss=0.01063, over 2436.00 frames. ], tot_loss[loss=0.01063, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:56,841 INFO [train.py:422] Epoch 12, batch 10, loss[loss=0.009072, over 2828.00 frames. ], tot_loss[loss=0.01008, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:57,128 INFO [train.py:444] Epoch 12, validation loss=0.01096, over 18067.00 frames. \n","2023-10-11 17:06:57,520 INFO [train.py:422] Epoch 12, batch 20, loss[loss=0.01178, over 2695.00 frames. ], tot_loss[loss=0.01102, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:57,812 INFO [train.py:444] Epoch 12, validation loss=0.01083, over 18067.00 frames. \n","2023-10-11 17:06:57,850 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-12.pt\n","2023-10-11 17:06:57,907 INFO [train.py:422] Epoch 13, batch 0, loss[loss=0.0105, over 2436.00 frames. ], tot_loss[loss=0.0105, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:58,318 INFO [train.py:422] Epoch 13, batch 10, loss[loss=0.009003, over 2828.00 frames. ], tot_loss[loss=0.009956, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:06:58,609 INFO [train.py:444] Epoch 13, validation loss=0.01089, over 18067.00 frames. \n","2023-10-11 17:06:58,999 INFO [train.py:422] Epoch 13, batch 20, loss[loss=0.01172, over 2695.00 frames. ], tot_loss[loss=0.01048, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:06:59,293 INFO [train.py:444] Epoch 13, validation loss=0.01089, over 18067.00 frames. \n","2023-10-11 17:06:59,329 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-13.pt\n","2023-10-11 17:06:59,385 INFO [train.py:422] Epoch 14, batch 0, loss[loss=0.01046, over 2436.00 frames. ], tot_loss[loss=0.01046, over 2436.00 frames. ], batch size: 4\n","2023-10-11 17:06:59,780 INFO [train.py:422] Epoch 14, batch 10, loss[loss=0.009051, over 2828.00 frames. ], tot_loss[loss=0.009946, over 22192.90 frames. ], batch size: 4\n","2023-10-11 17:07:00,065 INFO [train.py:444] Epoch 14, validation loss=0.01077, over 18067.00 frames. \n","2023-10-11 17:07:00,473 INFO [train.py:422] Epoch 14, batch 20, loss[loss=0.01173, over 2695.00 frames. ], tot_loss[loss=0.0104, over 34971.47 frames. ], batch size: 5\n","2023-10-11 17:07:00,783 INFO [train.py:444] Epoch 14, validation loss=0.01077, over 18067.00 frames. \n","2023-10-11 17:07:00,819 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-14.pt\n","2023-10-11 17:07:00,821 INFO [train.py:555] Done!\n"]}],"source":["! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n","  cd /content/icefall/egs/yesno/ASR && \\\n","  ./tdnn/train.py"]},{"cell_type":"markdown","metadata":{"id":"XnwI18BKcq6e"},"source":["## Decoding"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"-WS-i2RdYzrx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697048270759,"user_tz":-120,"elapsed":9406,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"17b7dc34-518f-4ce4-9718-6ce78bac136f"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-11 18:17:40,648 INFO [decode.py:262] Decoding started\n","2023-10-11 18:17:40,649 INFO [decode.py:263] {'exp_dir': PosixPath('tdnn/exp'), 'lang_dir': PosixPath('data/lang_phone'), 'feature_dim': 23, 'search_beam': 20, 'output_beam': 8, 'min_active_states': 30, 'max_active_states': 10000, 'use_double_scores': True, 'epoch': 14, 'avg': 2, 'export': False, 'feature_dir': PosixPath('data/fbank'), 'max_duration': 30.0, 'bucketing_sampler': False, 'num_buckets': 10, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': False, 'return_cuts': True, 'num_workers': 2, 'env_info': {'k2-version': '1.24.3', 'k2-build-type': 'Release', 'k2-with-cuda': True, 'k2-git-sha1': 'e400fa3b456faf8afe0ee5bfe572946b4921a3db', 'k2-git-date': 'Sat Jul 15 04:21:50 2023', 'lhotse-version': '1.17.0.dev+git.afc8eff.clean', 'torch-version': '2.0.1+cu118', 'torch-cuda-available': True, 'torch-cuda-version': '11.8', 'python-version': '3.1', 'icefall-git-branch': 'master', 'icefall-git-sha1': '2b3c5d7-clean', 'icefall-git-date': 'Wed Oct 11 08:58:00 2023', 'icefall-path': '/content/icefall', 'k2-path': '/usr/local/lib/python3.10/dist-packages/k2/__init__.py', 'lhotse-path': '/usr/local/lib/python3.10/dist-packages/lhotse/__init__.py', 'hostname': 'df0af0b2b89f', 'IP address': '172.28.0.12'}}\n","2023-10-11 18:17:40,649 INFO [lexicon.py:168] Loading pre-compiled data/lang_phone/Linv.pt\n","2023-10-11 18:17:40,650 INFO [decode.py:272] device: cuda:0\n","2023-10-11 18:17:42,354 INFO [decode.py:290] averaging ['tdnn/exp/epoch-13.pt', 'tdnn/exp/epoch-14.pt']\n","2023-10-11 18:17:42,357 INFO [asr_datamodule.py:218] About to get test cuts\n","2023-10-11 18:17:42,357 INFO [asr_datamodule.py:253] About to get test cuts\n","2023-10-11 18:17:44,372 INFO [decode.py:203] batch 0/?, cuts processed until now is 4\n","2023-10-11 18:17:45,798 INFO [decode.py:240] The transcripts are stored in tdnn/exp/recogs-test_set.txt\n","2023-10-11 18:17:45,800 INFO [utils.py:641] [test_set] %WER 0.42% [1 / 240, 0 ins, 1 del, 0 sub ]\n","2023-10-11 18:17:45,803 INFO [decode.py:248] Wrote detailed error stats to tdnn/exp/errs-test_set.txt\n","2023-10-11 18:17:45,803 INFO [decode.py:315] Done!\n"]}],"source":["! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n","  cd /content/icefall/egs/yesno/ASR && \\\n","  ./tdnn/decode.py"]},{"cell_type":"markdown","metadata":{"id":"OMENow4cc53b"},"source":["### Show the decoding result"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"4yQT-VEJc3Xz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044034864,"user_tz":-120,"elapsed":17,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"7ee2468d-877a-4ea9-d294-be6ba1275a3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["0_0_0_1_0_0_0_1-0:\tref=['NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES']\n","0_0_0_1_0_0_0_1-0:\thyp=['NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES']\n","0_0_1_0_0_0_1_0-1:\tref=['NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO']\n","0_0_1_0_0_0_1_0-1:\thyp=['NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO']\n","0_0_1_0_0_1_1_1-2:\tref=['NO', 'NO', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n","0_0_1_0_0_1_1_1-2:\thyp=['NO', 'NO', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n","0_0_1_0_1_0_0_1-3:\tref=['NO', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'YES']\n","0_0_1_0_1_0_0_1-3:\thyp=['NO', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'YES']\n","0_0_1_1_0_0_0_1-4:\tref=['NO', 'NO', 'YES', 'YES', 'NO', 'NO', 'NO', 'YES']\n","0_0_1_1_0_0_0_1-4:\thyp=['NO', 'NO', 'YES', 'YES', 'NO', 'NO', 'NO', 'YES']\n","0_0_1_1_0_1_1_0-5:\tref=['NO', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'NO']\n","0_0_1_1_0_1_1_0-5:\thyp=['NO', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'NO']\n","0_0_1_1_1_0_0_0-6:\tref=['NO', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n","0_0_1_1_1_0_0_0-6:\thyp=['NO', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n","0_0_1_1_1_1_0_0-7:\tref=['NO', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO']\n","0_0_1_1_1_1_0_0-7:\thyp=['NO', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO']\n","0_1_0_0_0_1_0_0-8:\tref=['NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO', 'NO']\n","0_1_0_0_0_1_0_0-8:\thyp=['NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO', 'NO']\n","0_1_0_0_1_0_1_0-9:\tref=['NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'NO']\n","0_1_0_0_1_0_1_0-9:\thyp=['NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'NO']\n","0_1_0_1_0_0_0_0-10:\tref=['NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'NO', 'NO']\n","0_1_0_1_0_0_0_0-10:\thyp=['NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'NO']\n","0_1_0_1_1_1_0_0-11:\tref=['NO', 'YES', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO']\n","0_1_0_1_1_1_0_0-11:\thyp=['NO', 'YES', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO']\n","0_1_1_0_0_1_1_1-12:\tref=['NO', 'YES', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n","0_1_1_0_0_1_1_1-12:\thyp=['NO', 'YES', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n","0_1_1_1_0_0_1_0-13:\tref=['NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n","0_1_1_1_0_0_1_0-13:\thyp=['NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n","0_1_1_1_1_0_1_0-14:\tref=['NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES', 'NO']\n","0_1_1_1_1_0_1_0-14:\thyp=['NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES', 'NO']\n","1_0_0_0_0_0_0_0-15:\tref=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO']\n","1_0_0_0_0_0_0_0-15:\thyp=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO']\n","1_0_0_0_0_0_1_1-16:\tref=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'YES', 'YES']\n","1_0_0_0_0_0_1_1-16:\thyp=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'YES', 'YES']\n","1_0_0_1_0_1_1_1-17:\tref=['YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES', 'YES']\n","1_0_0_1_0_1_1_1-17:\thyp=['YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES', 'YES']\n","1_0_1_1_0_1_1_1-18:\tref=['YES', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'YES']\n","1_0_1_1_0_1_1_1-18:\thyp=['YES', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'YES']\n","1_0_1_1_1_1_0_1-19:\tref=['YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES']\n","1_0_1_1_1_1_0_1-19:\thyp=['YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES']\n","1_1_0_0_0_1_1_1-20:\tref=['YES', 'YES', 'NO', 'NO', 'NO', 'YES', 'YES', 'YES']\n","1_1_0_0_0_1_1_1-20:\thyp=['YES', 'YES', 'NO', 'NO', 'NO', 'YES', 'YES', 'YES']\n","1_1_0_0_1_0_1_1-21:\tref=['YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES']\n","1_1_0_0_1_0_1_1-21:\thyp=['YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES']\n","1_1_0_1_0_1_0_0-22:\tref=['YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO']\n","1_1_0_1_0_1_0_0-22:\thyp=['YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO']\n","1_1_0_1_1_0_0_1-23:\tref=['YES', 'YES', 'NO', 'YES', 'YES', 'NO', 'NO', 'YES']\n","1_1_0_1_1_0_0_1-23:\thyp=['YES', 'YES', 'NO', 'YES', 'YES', 'NO', 'NO', 'YES']\n","1_1_0_1_1_1_1_0-24:\tref=['YES', 'YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO']\n","1_1_0_1_1_1_1_0-24:\thyp=['YES', 'YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO']\n","1_1_1_0_0_1_0_1-25:\tref=['YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES']\n","1_1_1_0_0_1_0_1-25:\thyp=['YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES']\n","1_1_1_0_1_0_1_0-26:\tref=['YES', 'YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO']\n","1_1_1_0_1_0_1_0-26:\thyp=['YES', 'YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO']\n","1_1_1_1_0_0_1_0-27:\tref=['YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n","1_1_1_1_0_0_1_0-27:\thyp=['YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n","1_1_1_1_1_0_0_0-28:\tref=['YES', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n","1_1_1_1_1_0_0_0-28:\thyp=['YES', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n","1_1_1_1_1_1_1_1-29:\tref=['YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES']\n","1_1_1_1_1_1_1_1-29:\thyp=['YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES']\n"]}],"source":["! cd /content/icefall/egs/yesno/ASR && \\\n","  cat tdnn/exp/recogs-test_set.txt"]},{"cell_type":"markdown","metadata":{"id":"1RIxtJ-IdLob"},"source":["### Show the detailed WER"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"0lQFBS-KdIVx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044034864,"user_tz":-120,"elapsed":15,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"5bf376d0-3cdf-4617-9958-826a743b6d32"},"outputs":[{"output_type":"stream","name":"stdout","text":["%WER = 0.42\n","Errors: 0 insertions, 1 deletions, 0 substitutions, over 240 reference words (239 correct)\n","Search below for sections starting with PER-UTT DETAILS:, SUBSTITUTIONS:, DELETIONS:, INSERTIONS:, PER-WORD STATS:\n","\n","PER-UTT DETAILS: corr or (ref->hyp)  \n","0_0_0_1_0_0_0_1-0:\tNO NO NO YES NO NO NO YES\n","0_0_1_0_0_0_1_0-1:\tNO NO YES NO NO NO YES NO\n","0_0_1_0_0_1_1_1-2:\tNO NO YES NO NO YES YES YES\n","0_0_1_0_1_0_0_1-3:\tNO NO YES NO YES NO NO YES\n","0_0_1_1_0_0_0_1-4:\tNO NO YES YES NO NO NO YES\n","0_0_1_1_0_1_1_0-5:\tNO NO YES YES NO YES YES NO\n","0_0_1_1_1_0_0_0-6:\tNO NO YES YES YES NO NO NO\n","0_0_1_1_1_1_0_0-7:\tNO NO YES YES YES YES NO NO\n","0_1_0_0_0_1_0_0-8:\tNO YES NO NO NO YES NO NO\n","0_1_0_0_1_0_1_0-9:\tNO YES NO NO YES NO YES NO\n","0_1_0_1_0_0_0_0-10:\tNO YES NO YES NO NO NO (NO->*)\n","0_1_0_1_1_1_0_0-11:\tNO YES NO YES YES YES NO NO\n","0_1_1_0_0_1_1_1-12:\tNO YES YES NO NO YES YES YES\n","0_1_1_1_0_0_1_0-13:\tNO YES YES YES NO NO YES NO\n","0_1_1_1_1_0_1_0-14:\tNO YES YES YES YES NO YES NO\n","1_0_0_0_0_0_0_0-15:\tYES NO NO NO NO NO NO NO\n","1_0_0_0_0_0_1_1-16:\tYES NO NO NO NO NO YES YES\n","1_0_0_1_0_1_1_1-17:\tYES NO NO YES NO YES YES YES\n","1_0_1_1_0_1_1_1-18:\tYES NO YES YES NO YES YES YES\n","1_0_1_1_1_1_0_1-19:\tYES NO YES YES YES YES NO YES\n","1_1_0_0_0_1_1_1-20:\tYES YES NO NO NO YES YES YES\n","1_1_0_0_1_0_1_1-21:\tYES YES NO NO YES NO YES YES\n","1_1_0_1_0_1_0_0-22:\tYES YES NO YES NO YES NO NO\n","1_1_0_1_1_0_0_1-23:\tYES YES NO YES YES NO NO YES\n","1_1_0_1_1_1_1_0-24:\tYES YES NO YES YES YES YES NO\n","1_1_1_0_0_1_0_1-25:\tYES YES YES NO NO YES NO YES\n","1_1_1_0_1_0_1_0-26:\tYES YES YES NO YES NO YES NO\n","1_1_1_1_0_0_1_0-27:\tYES YES YES YES NO NO YES NO\n","1_1_1_1_1_0_0_0-28:\tYES YES YES YES YES NO NO NO\n","1_1_1_1_1_1_1_1-29:\tYES YES YES YES YES YES YES YES\n","\n","SUBSTITUTIONS: count ref -> hyp\n","\n","DELETIONS: count ref\n","1   NO\n","\n","INSERTIONS: count hyp\n","\n","PER-WORD STATS: word  corr tot_errs count_in_ref count_in_hyp\n","NO   115 1 116 115\n","YES   124 0 124 124\n"]}],"source":["! cd /content/icefall/egs/yesno/ASR && \\\n","  cat tdnn/exp/errs-test_set.txt"]},{"cell_type":"markdown","metadata":{"id":"3lIChKjOr5J0"},"source":["# Pre-trained model"]},{"cell_type":"markdown","metadata":{"id":"nzfpY18xr-6P"},"source":["### Download the pre-trained model"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"naBI_K9fr8Qn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044039401,"user_tz":-120,"elapsed":4549,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"3fb259a0-d42f-451c-dea7-73ad90ac2cc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Updated git hooks.\n","Git LFS initialized.\n","Cloning into 'icefall_asr_yesno_tdnn'...\n","remote: Enumerating objects: 60, done.\u001b[K\n","remote: Total 60 (delta 0), reused 0 (delta 0), pack-reused 60\u001b[K\n","Unpacking objects: 100% (60/60), 2.28 MiB | 2.38 MiB/s, done.\n","Filtering content: 100% (5/5), 62.15 KiB | 24.00 KiB/s, done.\n"]}],"source":["! cd /content/icefall/egs/yesno/ASR && \\\n","  mkdir tmp && \\\n","  cd tmp && \\\n","  git lfs install && \\\n","  git clone https://huggingface.co/csukuangfj/icefall_asr_yesno_tdnn"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"8hbcze8EsRcA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044041598,"user_tz":-120,"elapsed":2199,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"c5866a09-be2f-4912-9e84-f72e7a0faaf4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n","0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"]}],"source":["! sudo apt-get install git-lfs"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"SCkos-5msW-K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044041598,"user_tz":-120,"elapsed":6,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"16c95bb2-6d49-4bb4-ca55-f111f2f46add"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: tree: command not found\n"]}],"source":["! cd /content/icefall/egs/yesno/ASR && \\\n","  mkdir -p tmp && \\\n","  tree tmp"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"ufKWViBxsc41","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044046035,"user_tz":-120,"elapsed":4440,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"49f20315-305c-46f6-fb05-fa8b4887d1be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  tree\n","0 upgraded, 1 newly installed, 0 to remove and 18 not upgraded.\n","Need to get 47.9 kB of archives.\n","After this operation, 116 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n","Fetched 47.9 kB in 1s (63.7 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package tree.\n","(Reading database ... 120875 files and directories currently installed.)\n","Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n","Unpacking tree (2.0.2-1) ...\n","Setting up tree (2.0.2-1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n"]}],"source":["! sudo apt-get install tree"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"rJn7iUw6se1W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044046036,"user_tz":-120,"elapsed":19,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"2df9b2a4-d0ab-4f30-95e8-53e48983dd10"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[01;34mtmp\u001b[0m\n","└── \u001b[01;34micefall_asr_yesno_tdnn\u001b[0m\n","    ├── \u001b[01;34mlang_phone\u001b[0m\n","    │   ├── \u001b[00mHLG.pt\u001b[0m\n","    │   ├── \u001b[00mL_disambig.pt\u001b[0m\n","    │   ├── \u001b[00mlexicon_disambig.txt\u001b[0m\n","    │   ├── \u001b[00mlexicon.txt\u001b[0m\n","    │   ├── \u001b[00mLinv.pt\u001b[0m\n","    │   ├── \u001b[00mL.pt\u001b[0m\n","    │   ├── \u001b[00mtokens.txt\u001b[0m\n","    │   └── \u001b[00mwords.txt\u001b[0m\n","    ├── \u001b[01;34mlm\u001b[0m\n","    │   ├── \u001b[00mG.arpa\u001b[0m\n","    │   └── \u001b[00mG.fst.txt\u001b[0m\n","    ├── \u001b[00mpretrained.pt\u001b[0m\n","    ├── \u001b[00mREADME.md\u001b[0m\n","    └── \u001b[01;34mtest_waves\u001b[0m\n","        ├── \u001b[01;35m0_0_0_1_0_0_0_1.wav\u001b[0m\n","        ├── \u001b[01;35m0_0_1_0_0_0_1_0.wav\u001b[0m\n","        ├── \u001b[01;35m0_0_1_0_0_1_1_1.wav\u001b[0m\n","        ├── \u001b[01;35m0_0_1_0_1_0_0_1.wav\u001b[0m\n","        ├── \u001b[01;35m0_0_1_1_0_0_0_1.wav\u001b[0m\n","        ├── \u001b[01;35m0_0_1_1_0_1_1_0.wav\u001b[0m\n","        ├── \u001b[01;35m0_0_1_1_1_0_0_0.wav\u001b[0m\n","        ├── \u001b[01;35m0_0_1_1_1_1_0_0.wav\u001b[0m\n","        ├── \u001b[01;35m0_1_0_0_0_1_0_0.wav\u001b[0m\n","        ├── \u001b[01;35m0_1_0_0_1_0_1_0.wav\u001b[0m\n","        ├── \u001b[01;35m0_1_0_1_0_0_0_0.wav\u001b[0m\n","        ├── \u001b[01;35m0_1_0_1_1_1_0_0.wav\u001b[0m\n","        ├── \u001b[01;35m0_1_1_0_0_1_1_1.wav\u001b[0m\n","        ├── \u001b[01;35m0_1_1_1_0_0_1_0.wav\u001b[0m\n","        ├── \u001b[01;35m0_1_1_1_1_0_1_0.wav\u001b[0m\n","        ├── \u001b[01;35m1_0_0_0_0_0_0_0.wav\u001b[0m\n","        ├── \u001b[01;35m1_0_0_0_0_0_1_1.wav\u001b[0m\n","        ├── \u001b[01;35m1_0_0_1_0_1_1_1.wav\u001b[0m\n","        ├── \u001b[01;35m1_0_1_1_0_1_1_1.wav\u001b[0m\n","        ├── \u001b[01;35m1_0_1_1_1_1_0_1.wav\u001b[0m\n","        ├── \u001b[01;35m1_1_0_0_0_1_1_1.wav\u001b[0m\n","        ├── \u001b[01;35m1_1_0_0_1_0_1_1.wav\u001b[0m\n","        ├── \u001b[01;35m1_1_0_1_0_1_0_0.wav\u001b[0m\n","        ├── \u001b[01;35m1_1_0_1_1_0_0_1.wav\u001b[0m\n","        ├── \u001b[01;35m1_1_0_1_1_1_1_0.wav\u001b[0m\n","        ├── \u001b[01;35m1_1_1_0_0_1_0_1.wav\u001b[0m\n","        ├── \u001b[01;35m1_1_1_0_1_0_1_0.wav\u001b[0m\n","        ├── \u001b[01;35m1_1_1_1_0_0_1_0.wav\u001b[0m\n","        ├── \u001b[01;35m1_1_1_1_1_0_0_0.wav\u001b[0m\n","        └── \u001b[01;35m1_1_1_1_1_1_1_1.wav\u001b[0m\n","\n","4 directories, 42 files\n"]}],"source":["! cd /content/icefall/egs/yesno/ASR && \\\n","  mkdir -p tmp && \\\n","  tree tmp"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"69CgbooXsorj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044053719,"user_tz":-120,"elapsed":7694,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"89e07276-68fa-4bde-d533-7cb8e6fed554"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base\n","  libsox3 libwavpack1\n","Suggested packages:\n","  libsox-fmt-all\n","The following NEW packages will be installed:\n","  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base\n","  libsox3 libwavpack1 sox\n","0 upgraded, 7 newly installed, 0 to remove and 18 not upgraded.\n","Need to get 617 kB of archives.\n","After this operation, 1,764 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [240 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [11.2 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [33.7 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 sox amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [104 kB]\n","Fetched 617 kB in 2s (305 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 7.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libopencore-amrnb0:amd64.\n","(Reading database ... 120883 files and directories currently installed.)\n","Preparing to unpack .../0-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n","Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n","Selecting previously unselected package libopencore-amrwb0:amd64.\n","Preparing to unpack .../1-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n","Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n","Selecting previously unselected package libsox3:amd64.\n","Preparing to unpack .../2-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n","Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Selecting previously unselected package libsox-fmt-alsa:amd64.\n","Preparing to unpack .../3-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n","Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Selecting previously unselected package libwavpack1:amd64.\n","Preparing to unpack .../4-libwavpack1_5.4.0-1build2_amd64.deb ...\n","Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n","Selecting previously unselected package libsox-fmt-base:amd64.\n","Preparing to unpack .../5-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n","Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Selecting previously unselected package sox.\n","Preparing to unpack .../6-sox_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n","Unpacking sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n","Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n","Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n","Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Setting up sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n"]}],"source":["! sudo apt-get install sox"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"MRQ85XoTsqVq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044053720,"user_tz":-120,"elapsed":9,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"176228ff-3bb5-4a1a-eb55-6290bd79a8ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Input File     : 'tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav'\n","Channels       : 1\n","Sample Rate    : 8000\n","Precision      : 16-bit\n","Duration       : 00:00:06.76 = 54080 samples ~ 507 CDDA sectors\n","File Size      : 108k\n","Bit Rate       : 128k\n","Sample Encoding: 16-bit Signed Integer PCM\n","\n"]}],"source":["! cd /content/icefall/egs/yesno/ASR && \\\n","  soxi tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav"]},{"cell_type":"markdown","metadata":{"id":"QtEYXq6Lt4gH"},"source":["## Download kaldifeat\n","\n","See https://csukuangfj.github.io/kaldifeat/installation/from_wheels.html"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"0yXGrYBbt7Xd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044060820,"user_tz":-120,"elapsed":7104,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"e7b61fad-ee47-40c8-dd8c-d44491500007"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://csukuangfj.github.io/kaldifeat/cuda.html\n","Collecting kaldifeat==1.25.0.dev20230726+cuda11.8.torch2.0.1\n","  Downloading https://huggingface.co/csukuangfj/kaldifeat/resolve/main/ubuntu-cuda/kaldifeat-1.25.0.dev20230726%2Bcuda11.8.torch2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (574 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m574.0/574.0 kB\u001b[0m \u001b[31m609.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: kaldifeat\n","Successfully installed kaldifeat-1.25.0.dev20230726+cuda11.8.torch2.0.1\n"]}],"source":["! pip install kaldifeat==1.25.0.dev20230726+cuda11.8.torch2.0.1  -f https://csukuangfj.github.io/kaldifeat/cuda.html"]},{"cell_type":"markdown","metadata":{"id":"QWmnk4YwsyQn"},"source":["## Inference with a pre-trained model\n"]},{"cell_type":"markdown","metadata":{"id":"l-YdwbyfwS7F"},"source":["### View help information"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"ZmU6_ZbLsvAg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044063900,"user_tz":-120,"elapsed":3084,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"14ebe019-aff3-4719-a7a4-a468f5267fb0"},"outputs":[{"output_type":"stream","name":"stdout","text":["usage: pretrained.py\n","       [-h]\n","       --checkpoint\n","       CHECKPOINT\n","       --words-file\n","       WORDS_FILE\n","       --HLG\n","       HLG\n","       sound_files\n","       [sound_files ...]\n","\n","positional arguments:\n","  sound_files\n","    The input\n","    sound\n","    file(s) to\n","    transcribe.\n","    Supported\n","    formats are\n","    those\n","    supported\n","    by torchaud\n","    io.load().\n","    For\n","    example,\n","    wav and\n","    flac are\n","    supported.\n","\n","options:\n","  -h, --help\n","    show this\n","    help\n","    message and\n","    exit\n","  --checkpoint CHECKPOINT\n","    Path to the\n","    checkpoint.\n","    The\n","    checkpoint\n","    is assumed\n","    to be saved\n","    by icefall.\n","    checkpoint.\n","    save_checkp\n","    oint(). You\n","    can use ./t\n","    dnn/export.\n","    py to\n","    obtain it.\n","    (default:\n","    None)\n","  --words-file WORDS_FILE\n","    Path to\n","    words.txt\n","    (default:\n","    None)\n","  --HLG HLG\n","    Path to\n","    HLG.pt.\n","    (default:\n","    None)\n"]}],"source":["! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n","  cd /content/icefall/egs/yesno/ASR && \\\n","  ./tdnn/pretrained.py --help"]},{"cell_type":"markdown","metadata":{"id":"R2zEQaGxwUob"},"source":["### Decode a single sound file"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"qxMbwNH0s9Sl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044071314,"user_tz":-120,"elapsed":7417,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"4e19aa51-d307-4dd8-a60e-d038f115825b"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-11 17:07:41,996 INFO [pretrained.py:136] {'feature_dim': 23, 'num_classes': 4, 'sample_rate': 8000, 'search_beam': 20, 'output_beam': 8, 'min_active_states': 30, 'max_active_states': 10000, 'use_double_scores': True, 'checkpoint': './tmp/icefall_asr_yesno_tdnn/pretrained.pt', 'words_file': './tmp/icefall_asr_yesno_tdnn/lang_phone/words.txt', 'HLG': './tmp/icefall_asr_yesno_tdnn/lang_phone/HLG.pt', 'sound_files': ['./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav']}\n","2023-10-11 17:07:42,016 INFO [pretrained.py:142] device: cuda:0\n","2023-10-11 17:07:42,016 INFO [pretrained.py:144] Creating model\n","2023-10-11 17:07:43,718 INFO [pretrained.py:156] Loading HLG from ./tmp/icefall_asr_yesno_tdnn/lang_phone/HLG.pt\n","2023-10-11 17:07:43,720 INFO [pretrained.py:160] Constructing Fbank computer\n","2023-10-11 17:07:43,721 INFO [pretrained.py:170] Reading sound files: ['./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav']\n","2023-10-11 17:07:43,722 INFO [pretrained.py:176] Decoding started\n","2023-10-11 17:07:46,627 INFO [pretrained.py:212] \n","./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav:\n","NO NO YES NO YES NO NO YES\n","\n","\n","2023-10-11 17:07:46,627 INFO [pretrained.py:214] Decoding Done\n"]}],"source":["! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n","  cd /content/icefall/egs/yesno/ASR && \\\n","  ./tdnn/pretrained.py \\\n","    --checkpoint ./tmp/icefall_asr_yesno_tdnn/pretrained.pt \\\n","    --words-file ./tmp/icefall_asr_yesno_tdnn/lang_phone/words.txt \\\n","    --HLG ./tmp/icefall_asr_yesno_tdnn/lang_phone/HLG.pt \\\n","    ./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav"]},{"cell_type":"markdown","metadata":{"id":"ZxT9rP6WwXdO"},"source":["### Decode multiple sound files"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"H6bYzDehvWZI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697044077419,"user_tz":-120,"elapsed":6109,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"97f168db-f8f0-4fde-f7a9-193af6f5904b"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-11 17:07:50,283 INFO [pretrained.py:136] {'feature_dim': 23, 'num_classes': 4, 'sample_rate': 8000, 'search_beam': 20, 'output_beam': 8, 'min_active_states': 30, 'max_active_states': 10000, 'use_double_scores': True, 'checkpoint': './tmp/icefall_asr_yesno_tdnn/pretrained.pt', 'words_file': './tmp/icefall_asr_yesno_tdnn/lang_phone/words.txt', 'HLG': './tmp/icefall_asr_yesno_tdnn/lang_phone/HLG.pt', 'sound_files': ['./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav', './tmp/icefall_asr_yesno_tdnn/test_waves/1_0_1_1_0_1_1_1.wav']}\n","2023-10-11 17:07:50,301 INFO [pretrained.py:142] device: cuda:0\n","2023-10-11 17:07:50,301 INFO [pretrained.py:144] Creating model\n","2023-10-11 17:07:52,020 INFO [pretrained.py:156] Loading HLG from ./tmp/icefall_asr_yesno_tdnn/lang_phone/HLG.pt\n","2023-10-11 17:07:52,023 INFO [pretrained.py:160] Constructing Fbank computer\n","2023-10-11 17:07:52,023 INFO [pretrained.py:170] Reading sound files: ['./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav', './tmp/icefall_asr_yesno_tdnn/test_waves/1_0_1_1_0_1_1_1.wav']\n","2023-10-11 17:07:52,025 INFO [pretrained.py:176] Decoding started\n","2023-10-11 17:07:53,636 INFO [pretrained.py:212] \n","./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav:\n","NO NO YES NO YES NO NO YES\n","\n","./tmp/icefall_asr_yesno_tdnn/test_waves/1_0_1_1_0_1_1_1.wav:\n","YES NO YES YES NO YES YES YES\n","\n","\n","2023-10-11 17:07:53,636 INFO [pretrained.py:214] Decoding Done\n"]}],"source":["! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n","  cd /content/icefall/egs/yesno/ASR && \\\n","  ./tdnn/pretrained.py \\\n","    --checkpoint ./tmp/icefall_asr_yesno_tdnn/pretrained.pt \\\n","    --words-file ./tmp/icefall_asr_yesno_tdnn/lang_phone/words.txt \\\n","    --HLG ./tmp/icefall_asr_yesno_tdnn/lang_phone/HLG.pt \\\n","    ./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav \\\n","    ./tmp/icefall_asr_yesno_tdnn/test_waves/1_0_1_1_0_1_1_1.wav"]},{"cell_type":"code","source":["cd /content/icefall/egs/yesno/ASR/tdnn/exp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vM08wMTn0N4u","executionInfo":{"status":"ok","timestamp":1697045927810,"user_tz":-120,"elapsed":5,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"dff12d95-8a7c-4966-9324-91d769d57490"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/icefall/egs/yesno/ASR/tdnn/exp\n"]}]},{"cell_type":"code","source":["ls -la"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_WTuRRFu0anj","executionInfo":{"status":"ok","timestamp":1697045932122,"user_tz":-120,"elapsed":438,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"1137e755-f25a-4c6a-b17e-097100426ac5"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["total 1048\n","drwxr-xr-x 4 root root  4096 Oct 11 17:07 \u001b[0m\u001b[01;34m.\u001b[0m/\n","drwxr-xr-x 4 root root  4096 Oct 11 17:06 \u001b[01;34m..\u001b[0m/\n","-rw-r--r-- 1 root root 59141 Oct 11 17:07 best-train-loss.pt\n","-rw-r--r-- 1 root root 59141 Oct 11 17:07 best-valid-loss.pt\n","-rw-r--r-- 1 root root 58674 Oct 11 17:06 epoch-0.pt\n","-rw-r--r-- 1 root root 59141 Oct 11 17:06 epoch-10.pt\n","-rw-r--r-- 1 root root 59141 Oct 11 17:06 epoch-11.pt\n","-rw-r--r-- 1 root root 59141 Oct 11 17:06 epoch-12.pt\n","-rw-r--r-- 1 root root 59141 Oct 11 17:06 epoch-13.pt\n","-rw-r--r-- 1 root root 59141 Oct 11 17:07 epoch-14.pt\n","-rw-r--r-- 1 root root 58674 Oct 11 17:06 epoch-1.pt\n","-rw-r--r-- 1 root root 58674 Oct 11 17:06 epoch-2.pt\n","-rw-r--r-- 1 root root 58674 Oct 11 17:06 epoch-3.pt\n","-rw-r--r-- 1 root root 58674 Oct 11 17:06 epoch-4.pt\n","-rw-r--r-- 1 root root 58674 Oct 11 17:06 epoch-5.pt\n","-rw-r--r-- 1 root root 58674 Oct 11 17:06 epoch-6.pt\n","-rw-r--r-- 1 root root 58674 Oct 11 17:06 epoch-7.pt\n","-rw-r--r-- 1 root root 58674 Oct 11 17:06 epoch-8.pt\n","-rw-r--r-- 1 root root 58674 Oct 11 17:06 epoch-9.pt\n","-rw-r--r-- 1 root root  1883 Oct 11 17:07 errs-test_set.txt\n","drwxr-xr-x 2 root root  4096 Oct 11 17:07 \u001b[01;34mlog\u001b[0m/\n","-rw-r--r-- 1 root root  4602 Oct 11 17:07 recogs-test_set.txt\n","drwxr-xr-x 2 root root  4096 Oct 11 17:06 \u001b[01;34mtensorboard\u001b[0m/\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"kernel_myenv","language":"python","name":"kernel_myenv"},"language_info":{"name":"python","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}